{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Vehicles from Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook performs the task of **taking a video file as input**, and creating **cropped images of the objects detected in the video**.\n",
    "\n",
    "These cropped images are created as training data for a Deep Learning model. The images will be further labeled into 3 classes - \n",
    "1. 2 or 3 wheelers (motorbikes, rickshaws, etc.)\n",
    "2. 4 wheelers (cars)\n",
    "3. 4+ wheelers (buses, trucks, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall workflow of this demonstration is as follows:\n",
    "\n",
    "- We first define some **global variables** that will be used through the entire demo\n",
    "- Then, we **define functions** that will be used during execution.\n",
    "- As soon as you run the **while loop** in the main function, the **first frame of the video is initialised**.\n",
    "- Using your mouse, you will **draw a line across one side of the road**. This will appear as a yellow line.\n",
    "- Once you draw the line, the video will start running.\n",
    "- Then, the video will keep running, and **vehicle images will get cropped** and get saved on a specified path.\n",
    "- When the **vehicle count reaches a certain threshold**, the video will stop.\n",
    "- All the cropped images will get saved on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run these if OpenCV doesn't load\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cv2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define variables that will be used through the duration of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable is created so that we can print necessary values while debugging.\n",
    "# Creating this variable is good general practice.\n",
    "SHOW_DEBUG_STEPS = False\n",
    "\n",
    "# This is a boolean variable which decides if a line has been dragged across or not\n",
    "drag = 0\n",
    "\n",
    "# This decides if a point has been selected or not\n",
    "select_flag = 0\n",
    "\n",
    "# These two points will be the endpoints of the line that we draw\n",
    "x1=0\n",
    "y1=0\n",
    "x2=1\n",
    "y2=1\n",
    "point1 = [x1,y1]\n",
    "point2 = [x2,y2]\n",
    "\n",
    "# This is a matrix version of the same two points\n",
    "crossingLine = np.zeros((2,2),np.int)\n",
    "crossingLine[0] = point1\n",
    "crossingLine[1] = point2\n",
    "\n",
    "# This is a boolean variable which determines if the frame is the first frame or not\n",
    "blnfFrame = True\n",
    "\n",
    "# Frame count is initialised (This is not initialised to 1 - we throw away the first frame after we draw a line on it)\n",
    "frameCnt = 2\n",
    "\n",
    "# This is a variable that's evoked when we are drawing the line on the frame\n",
    "callback = False\n",
    "\n",
    "# The count of vehicles is initialised to 0\n",
    "vehicleCount = 0\n",
    "\n",
    "# This is the title of the window where the video will play\n",
    "src_window='Vehicle Counting - Blob Save'\n",
    "\n",
    "# This is a variable that keeps track of how many blobs have been cropped\n",
    "u=0\n",
    "\n",
    "# Here, we define some colours\n",
    "SCALAR_BLACK = (0.0,0.0,0.0)\n",
    "SCALAR_WHITE = (255.0,255.0,255.0)\n",
    "SCALAR_YELLOW = (0.0,255.0,255.0)\n",
    "SCALAR_GREEN = (0.0,255.0,0.0)\n",
    "SCALAR_RED = (0.0,0.0,255.0)\n",
    "SCALAR_CYAN = (255.0,255.0,0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we define the 'Blob' class. \n",
    "\n",
    "This has two functions as a part of it: \n",
    "\n",
    "- 'Blob', which defines a blob object\n",
    "- 'predictNextPosition', which predicts the position of the blob in the next frame. This is useful for keeping track that given a frame and a blob, is it a new blob or a previously detected one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Blob:\n",
    "    currentContour = [[0,0]]\n",
    "    x=0\n",
    "    y=0\n",
    "    w=0\n",
    "    h=0\n",
    "    currentBoundingRect = [x,y,w,h] # = cv2.boundingRect(_contour)\n",
    "    centerPositions = [0,0]\n",
    "    dblCurrentDiagonalSize = 0.0\n",
    "    dblCurrentAspectRatio = 0.0\n",
    "    blnCurrentMatchFoundOrNewBlob = False\n",
    "    blnStillBeingTracked = False\n",
    "    intNumOfConsecutiveFramesWithoutAMatch = 0\n",
    "    predictedNextPosition = np.zeros((1,2),np.int)\n",
    "    \n",
    "    # First, let's define the 'Blob' function, which creates a 'Blob', with all the necessary parameters\n",
    "    \n",
    "    def Blob(self,_contour):\n",
    "        self.currentContour = _contour\n",
    "        self.currentBoundingRect = cv2.boundingRect(_contour)\n",
    "        currentCenter = [0,0]\n",
    "        \n",
    "        # This variable defines the center of the blob\n",
    "        currentCenter[0] = self.currentBoundingRect[0] + self.currentBoundingRect[2] / 2\n",
    "        currentCenter[1] = self.currentBoundingRect[1] + self.currentBoundingRect[3] / 2\n",
    "        \n",
    "        # This is a list of all the center positions of all the blobs.\n",
    "        self.centerPositions.append(currentCenter)\n",
    "        \n",
    "        # These parameters are used to define constraints on blob parameters. \n",
    "        self.dblCurrentDiagonalSize = math.sqrt(math.pow(self.currentBoundingRect[2],2) + math.pow(self.currentBoundingRect[3],2))\n",
    "        self.dblCurrentAspectRatio = float(self.currentBoundingRect[2]) / float(self.currentBoundingRect[3]) \n",
    "        \n",
    "        \n",
    "        self.blnStillBeingTracked = True\n",
    "        self.blnCurrentMatchFoundOrNewBlob = True\n",
    "        \n",
    "        self.intNumOfConsecutiveFramesWithoutAMatch = 0\n",
    "        \n",
    "    \n",
    "    # Next, we define a function that predicts the next position of the blob\n",
    "    # This function takes the position of blobs detected in a frame\n",
    "    # Then it predicts the position of that same blob in subsequent\n",
    "        \n",
    "    def predictNextPosition(self):\n",
    "        numPositions = int(len(self.centerPositions))\n",
    "                    \n",
    "        #self.predictedNextPosition[:]=[] \n",
    "        if(numPositions==1):\n",
    "            self.predictedNextPosition[0][0]=self.centerPositions[-1][0] # or [-1:]\n",
    "            self.predictedNextPosition[0][1]=self.centerPositions[-1][1]\n",
    "        elif(numPositions==2):\n",
    "            deltaX = self.centerPositions[1][0] - self.centerPositions[0][0]\n",
    "            deltaY = self.centerPositions[1][1] - self.centerPositions[0][1]\n",
    "            self.predictedNextPosition[0][0]=self.centerPositions[-1][0] + deltaX # or [-1:]\n",
    "            self.predictedNextPosition[0][1]=self.centerPositions[-1][1] + deltaY\n",
    "        elif(numPositions==3):\n",
    "            sumOfXChanges = ((self.centerPositions[2][0] - self.centerPositions[1][0])*2) + ((self.centerPositions[1][0] - self.centerPositions[0][0])*1)\n",
    "            deltaX = int(round(float(sumOfXChanges/3.0)+0.5))\n",
    "            sumOfYChanges = ((self.centerPositions[2][1] - self.centerPositions[1][1]) * 2) + ((self.centerPositions[1][1] - self.centerPositions[0][1]) * 1)\n",
    "            deltaY = int(round(float(sumOfYChanges/3.0)+0.5))\n",
    "            self.predictedNextPosition[0][0]=self.centerPositions[-1][0] + deltaX # or [-1:]\n",
    "            self.predictedNextPosition[0][1]=self.centerPositions[-1][1] + deltaY\n",
    "        elif(numPositions==4):\n",
    "            sumOfXChanges = ((self.centerPositions[3][0] - self.centerPositions[2][0]) * 3) + ((self.centerPositions[2][0] - self.centerPositions[1][0]) * 2) + ((self.centerPositions[1][0] - self.centerPositions[0][0]) * 1)\n",
    "            deltaX = int(round(float(sumOfXChanges/6.0)+0.5))\n",
    "            sumOfYChanges = ((self.centerPositions[3][1] - self.centerPositions[2][1]) * 3) + ((self.centerPositions[2][1] - self.centerPositions[1][1]) * 2) + ((self.centerPositions[1][1] - self.centerPositions[0][1]) * 1)\n",
    "            deltaY = int(round(float(sumOfYChanges/6.0)+0.5))\n",
    "            self.predictedNextPosition[0][0]=self.centerPositions[-1][0] + deltaX # or [-1:]\n",
    "            self.predictedNextPosition[0][1]=self.centerPositions[-1][1] + deltaY\n",
    "        elif(numPositions>=5):\n",
    "            sumOfXChanges = ((self.centerPositions[numPositions-1][0] - self.centerPositions[numPositions-2][0]) * 4) + ((self.centerPositions[numPositions-2][0] - self.centerPositions[numPositions-3][0]) * 3) + ((self.centerPositions[numPositions-3][0] - self.centerPositions[numPositions-4][0]) * 2) + ((self.centerPositions[numPositions-4][0] - self.centerPositions[numPositions-5][0]) * 1)\n",
    "            deltaX = int(round(float(sumOfXChanges/10.0)+0.5))\n",
    "            sumOfYChanges = ((self.centerPositions[numPositions-1][1] - self.centerPositions[numPositions-2][1]) * 4) + ((self.centerPositions[numPositions-2][1] - self.centerPositions[numPositions-3][1]) * 3) + ((self.centerPositions[numPositions-3][1] - self.centerPositions[numPositions-4][1]) * 2) + ((self.centerPositions[numPositions-4][1] - self.centerPositions[numPositions-5][1]) * 1)\n",
    "            deltaY = int(round(float(sumOfYChanges/10.0)+0.5))\n",
    "            self.predictedNextPosition[0][0]=self.centerPositions[-1][0] + deltaX # or [-1:]\n",
    "            self.predictedNextPosition[0][1]=self.centerPositions[-1][1] + deltaY\n",
    "        else:\n",
    "            print (\"Shouldn't come here\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define all the functions that are used in this demo. If you individually read them, they will be hard to understand.\n",
    "\n",
    "The recommended way to read this notebook is as follows:\n",
    "1. Scroll down first to the **main function**.\n",
    "2. **Start reading** through the main function.\n",
    "3. Whenever you **encounter a new function, find the function name** (do a Ctrl-F (Cmd-F for Mac) with that function name\n",
    "4. This will help you **locate the function's definition**. \n",
    "5. Then **read through that definition** and understand how the function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "blob = Blob()\n",
    "blobs = [blob]\n",
    "\n",
    "\n",
    "# This function closes all the windows that are open with either video or images in them\n",
    "\n",
    "def closeAll():\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "# This functions checks if the video is corrupted\n",
    "    \n",
    "def retn(ret):\n",
    "    if not ret == True:\n",
    "        print(\"Error reading frame\")\n",
    "        closeAll()\n",
    "\n",
    "# This functions checks if the first frame is missing        \n",
    "        \n",
    "def frm(frame):\n",
    "    if fFrame is None:\n",
    "        print(\"Error reading frame\")\n",
    "        closeAll()\n",
    "        \n",
    "# This function is used to draw the yellow line on the first frame.\n",
    "# This yellow line acts as the boundary - if vehicles cross this line, they are counted as a blob\n",
    "        \n",
    "def drawMyLine(frame):\n",
    "    global point1\n",
    "    global point2\n",
    "    global SCALAR_YELLOW\n",
    "    cv2.line(frame,(point1[0],point1[1]),(point2[0],point2[1]),SCALAR_YELLOW,2,8)\n",
    "    \n",
    "\n",
    "    \n",
    "# This funtion checks if a vehicle is to the left of the line that we have drawn\n",
    "    \n",
    "def isLeftOfLineAB(a,b,c):\n",
    "    return ( (b[0]-a[0])*(c[1]-a[1]) - (b[1]-a[1])*(c[0]-a[0]) ) > 0\n",
    "\n",
    "# This mouse performs the actual drawing of the line\n",
    "\n",
    "def myMouseHandler(event,x,y,flags,param): # Click left button to start RoI selection\n",
    "    global point1\n",
    "    global point2\n",
    "    global drag\n",
    "    global select_flag\n",
    "    global callback\n",
    "    if (event == cv2.EVENT_LBUTTONDOWN and not(drag) and not(select_flag)):\n",
    "        point1 = [x,y]\n",
    "        drag = 1\n",
    "    \n",
    "    if (event == cv2.EVENT_MOUSEMOVE and drag and not(select_flag)): # Drag mouse to select RoI\n",
    "        img1 = fFrame.copy()\n",
    "        print ('img1 height' + str(img1.shape[0]))\n",
    "        print ('img1 width' + str(img1.shape[1]))\n",
    "        point2 = [x,y]\n",
    "        drawMyLine(fFrame)\n",
    "        cv2.imshow(src_window,img1) # why img1?\n",
    "        \n",
    "    if(event == cv2.EVENT_LBUTTONUP and drag and not(select_flag)): # Complete selection\n",
    "        img2 = fFrame.copy()\n",
    "        print ('img2 height' + str(img2.shape[0]))\n",
    "        print ('img2 width' + str(img2.shape[1]))\n",
    "        point2 = [x,y]\n",
    "        drag = 0\n",
    "        select_flag = 1\n",
    "        cv2.imshow(src_window,img2) # why img2?\n",
    "        callback = 1\n",
    "\n",
    "# This adds all the blobs in the current frame into the existing list of blobs         \n",
    "        \n",
    "def addBlobToExistingBlobs(currentFrameBlob, existingBlobs, intIndex):\n",
    "    existingBlobs[intIndex].currentContour = currentFrameBlob.currentContour\n",
    "    existingBlobs[intIndex].currentBoundingRect = currentFrameBlob.currentBoundingRect\n",
    "\n",
    "    existingBlobs[intIndex].centerPositions.append(currentFrameBlob.centerPositions[-1])\n",
    "\n",
    "    existingBlobs[intIndex].dblCurrentDiagonalSize = currentFrameBlob.dblCurrentDiagonalSize\n",
    "    existingBlobs[intIndex].dblCurrentAspectRatio = currentFrameBlob.dblCurrentAspectRatio\n",
    "\n",
    "    existingBlobs[intIndex].blnStillBeingTracked = True\n",
    "    existingBlobs[intIndex].blnCurrentMatchFoundOrNewBlob = True\n",
    "\n",
    "# This is a simple distance calculator    \n",
    "    \n",
    "def distanceBetweenPoints(point1, point2):\n",
    "    if(SHOW_DEBUG_STEPS):\n",
    "        print ('point1: '+str(type(point1))+'point1: '+str(point1))\n",
    "        print ('point2: '+str(type(point2))+'point2: '+str(point2))\n",
    "    intX = abs(point1[0] - point2[0][0])\n",
    "    intY = abs(point1[1] - point2[0][1])\n",
    "\n",
    "    return (math.sqrt(math.pow(intX, 2) + math.pow(intY, 2)))\n",
    "\n",
    "# This function checks that given a blob, has it been spotted in a previous frame before?\n",
    "        \n",
    "def matchCurrentFrameBlobsToExistingBlobs(existingBlobs, currentFrameBlobs):\n",
    "#    for existingBlob in existingBlobs:\n",
    "#        existingBlobs[existingBlob].blnCurrentMatchFoundOrNewBlob =  False\n",
    "#        existingBlobs[existingBlob].predictNextPosition()       \n",
    "        \n",
    "    for i in range (len(existingBlobs)):\n",
    "        existingBlobs[i].blnCurrentMatchFoundOrNewBlob =  False\n",
    "        existingBlobs[i].predictNextPosition()    \n",
    "        \n",
    "    for currentFrameBlob in currentFrameBlobs:\n",
    "        intIndexOfLeastDistance = 0\n",
    "        dblLeastDistance = 100000.0\n",
    "        \n",
    "        for i in range(len(existingBlobs)):\n",
    "            if existingBlobs[i].blnStillBeingTracked == True:\n",
    "                if(SHOW_DEBUG_STEPS):\n",
    "                    print (\"existingBlobs[i].predictedNextPosition: \" + str(type(existingBlobs[i].predictedNextPosition)))\n",
    "                    print (\"currentFrameBlob.centerPositions[-1]: \" + str(type(currentFrameBlob.centerPositions[-1])))\n",
    "                dblDistance = distanceBetweenPoints(currentFrameBlob.centerPositions[-1], existingBlobs[i].predictedNextPosition.tolist())\n",
    "                    \n",
    "                if dblDistance < dblLeastDistance:\n",
    "                    dblLeastDistance = dblDistance\n",
    "                    intIndexOfLeastDistance = i\n",
    "                    \n",
    "        if dblLeastDistance < currentFrameBlob.dblCurrentDiagonalSize * 0.5:\n",
    "            addBlobToExistingBlobs(currentFrameBlob, existingBlobs, intIndexOfLeastDistance)\n",
    "        else:\n",
    "            addNewBlob(currentFrameBlob, existingBlobs)\n",
    "    \n",
    "    for existingBlob in existingBlobs:\n",
    "        if existingBlob.blnCurrentMatchFoundOrNewBlob == False:\n",
    "            existingBlob.intNumOfConsecutiveFramesWithoutAMatch = existingBlob.intNumOfConsecutiveFramesWithoutAMatch + 1\n",
    "        if existingBlob.intNumOfConsecutiveFramesWithoutAMatch >= 5:\n",
    "            existingBlob.blnStillBeingTracked = False\n",
    "\n",
    "# This function adds the blob to the list of blobs in the existing frame\n",
    "\n",
    "def addNewBlob(currentFrameBlob, existingBlobs):\n",
    "\n",
    "    currentFrameBlob.blnCurrentMatchFoundOrNewBlob = True\n",
    "\n",
    "    existingBlobs.append(currentFrameBlob)\n",
    "                \n",
    "def drawAndShowContours(wd,ht,contours,strImgName):\n",
    "    global SCALAR_WHITE\n",
    "    global SHOW_DEBUG_STEPS\n",
    "    blank_image = np.zeros((ht,wd,3), np.uint8)\n",
    "    cv2.drawContours(blank_image,contours,-1,SCALAR_WHITE,-1)\n",
    "    \n",
    "    if(SHOW_DEBUG_STEPS):\n",
    "        cv2.imshow(strImgName,blank_image)\n",
    "    return blank_image\n",
    "        \n",
    "def drawAndShowBlobs(wd,ht,blobs,strImgName):\n",
    "    global SCALAR_WHITE\n",
    "    global SHOW_DEBUG_STEPS\n",
    "    blank_image = np.zeros((ht,wd,3), np.uint8)\n",
    "    \n",
    "    contours=[]\n",
    "    for blob in blobs:\n",
    "        if blob.blnStillBeingTracked == True:\n",
    "            contours.append(blob.currentContour)\n",
    "            \n",
    "    cv2.drawContours(blank_image,contours,-1,SCALAR_WHITE,-1)\n",
    "    \n",
    "    if(SHOW_DEBUG_STEPS):\n",
    "        cv2.imshow(strImgName,blank_image)\n",
    "    return blank_image    \n",
    "    \n",
    "def checkIfBlobsCrossedTheLine(blobs):\n",
    "    global point1\n",
    "    global point2\n",
    "    global vehicleCount\n",
    "    blnAtLeastOneBlobCrossedTheLine = False\n",
    "    \n",
    "    for blob in blobs:\n",
    "        if (blob.blnStillBeingTracked == True and len(blob.centerPositions) >= 2):\n",
    "            prevFrmIdx = int(len(blob.centerPositions)) - 2\n",
    "            currFrmIdx = int(len(blob.centerPositions)) - 1\n",
    "            \n",
    "            if(SHOW_DEBUG_STEPS):\n",
    "                print ('prevFrmIdx: '+str(prevFrmIdx))\n",
    "                print ('currFrmIdx: '+str(currFrmIdx))\n",
    "                print ('blob.centerPositions: '+str(blob.centerPositions[prevFrmIdx][1]))\n",
    "            c=[1,2]\n",
    "            d=[1,2]\n",
    "            #d[0]=blob.centerPositions[prevFrmIdx][0]\n",
    "            #d[1]=blob.centerPositions[prevFrmIdx][1]\n",
    "            d=blob.centerPositions[prevFrmIdx]\n",
    "            #c[0]=blob.centerPositions[currFrmIdx][0]\n",
    "            #c[1]=blob.centerPositions[currFrmIdx][1]\n",
    "            c=blob.centerPositions[currFrmIdx]\n",
    "            \n",
    "            if (isLeftOfLineAB(point1,point2,c) and not(isLeftOfLineAB(point1,point2,d))):\n",
    "                vehicleCount = vehicleCount + 1\n",
    "                blnAtLeastOneBlobCrossedTheLine = True\n",
    "    \n",
    "    return blnAtLeastOneBlobCrossedTheLine\n",
    "\n",
    "\n",
    "# This is the function that draws the blob we spot, onto an image\n",
    "        \n",
    "def drawBlobInfoOnImage(blobs, imgFrame2Copy, imgorg, frmCnt, fps):\n",
    "    global SCALAR_RED   \n",
    "    global u    \n",
    "    im_name = \"_\"\n",
    "    path = \"/Users/jaideepkhare/Documents/neural-networks/vehicle-detection/saved_images/\"    \n",
    "    \n",
    "    im_names = str(u)+'.jpg\\n'\n",
    "    \n",
    "    for blob in blobs:\n",
    "        if blob.blnStillBeingTracked == True:\n",
    "            x,y,w,h = blob.currentBoundingRect\n",
    "            cv2.rectangle(imgFrame2Copy, (x,y),(x+w,y+h), SCALAR_RED, 2) \n",
    "            condi = frmCnt%5\n",
    "            if (condi == 0):\n",
    "                img_1boundingbox = imgorg[y:y+h,x:x+w]\n",
    "                im_name = path+str(u)+\".jpg\"\n",
    "                resizedRoI = cv2.resize(img_1boundingbox, (50,50))\n",
    "                cv2.imwrite(im_name,resizedRoI)\n",
    "                if not(u==0):\n",
    "                    im_names = im_names + str(u)+'.jpg\\n'\n",
    "                u = u+1                \n",
    "                \n",
    "    for i in range (len(blobs)):\n",
    "        if blobs[i].blnStillBeingTracked == True:\n",
    "            x,y,w,h = blobs[i].currentBoundingRect\n",
    "            cv2.rectangle(imgFrame2Copy, (x,y),(x+w,y+h), SCALAR_RED, 2)\n",
    "            #if ((frmCnt-2)%(fps+1) == 0):\n",
    "            img_1boundingbox = imgorg[y:y+h,x:x+w]\n",
    "            im_name = path+str(u)+\".jpg\"\n",
    "            img_1boundingbox = cv2.resize(img_1boundingbox, (50,50))\n",
    "            cv2.imwrite(im_name,img_1boundingbox)\n",
    "            if not(u==0):\n",
    "                im_names = im_names + str(u)+'.jpg\\n'\n",
    "            u = u+1      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From below this, the main function begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height720\n",
      "width1280\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "\n",
    "cap = cv2.VideoCapture('/Users/jaideepkhare/Documents/neural-networks/vehicle-detection/AundhBridge.mp4')\n",
    "#cap = cv2.VideoCapture('/media/anand/STB_Data/Projects/ext_projects/Upgrad/Univ_bridge_from_pride.mp4')\n",
    "\n",
    "\n",
    "if not(cap.isOpened()):\n",
    "    print(\"Error reading file\")\n",
    "\n",
    "ret, fFrame  = cap.read()\n",
    "retn(ret)\n",
    "frm(fFrame)\n",
    "#fFrame = cv2.resize(fFrame, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "fGray = cv2.cvtColor(fFrame, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(src_window, fFrame)\n",
    "          \n",
    "ret, fFrame1 = cap.read()\n",
    "ret, fFrame2 = cap.read()\n",
    "print ('height' + str(fFrame1.shape[0]))\n",
    "print ('width' + str(fFrame1.shape[1]))\n",
    "#fFrame1 = cv2.resize(fFrame1, (0,0), fx=0.5, fy=0.5)\n",
    "#fFrame2 = cv2.resize(fFrame2, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "cv2.setMouseCallback(src_window,myMouseHandler)\n",
    "chChkEscKey = 0  \n",
    "k = 27    \n",
    "blnFirstFrame = True\n",
    "frameCnt = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the while loop. It is kept open as long as the OpenCV video object is kept open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img1 height720\n",
      "img1 width1280\n",
      "img2 height720\n",
      "img2 width1280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while(cap.isOpened()):\n",
    "    if(callback):\n",
    "        currentFrameBlob = Blob()\n",
    "        currentFrameBlobs = [currentFrameBlob]\n",
    "        img1 = fFrame1.copy()\n",
    "        img2 = fFrame2.copy()\n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            print ('img1 height' + str(img1.shape[0]))\n",
    "            print ('img1 width' + str(img1.shape[1]))\n",
    "            print ('img2 height' + str(img2.shape[0]))\n",
    "            print ('img2 width' + str(img2.shape[1]))\n",
    "            \n",
    "        # Convert the images to colour in order to enable fast processing    \n",
    "        \n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Add some Gaussian Blur\n",
    "        \n",
    "        img1 = cv2.GaussianBlur(img1,(5,5),0)\n",
    "        img2 = cv2.GaussianBlur(img2,(5,5),0)\n",
    "        \n",
    "        \n",
    "        # This imgDiff variable is the difference between consecutive frames, which is equivalent to detecting movement\n",
    "        \n",
    "        imgDiff = cv2.absdiff(img1, img2) \n",
    "        \n",
    "        ret,imgThresh = cv2.threshold(imgDiff,30.0,255.0,cv2.THRESH_BINARY)\n",
    "        ht = np.size(imgThresh,0)\n",
    "        wd = np.size(imgThresh,1)\n",
    "        \n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            cv2.imshow('imgThresh', imgThresh) \n",
    "        \n",
    "        \n",
    "        # Now, we define structuring elements\n",
    "            \n",
    "        strucEle3x3 = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "        strucEle5x5 = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "        strucEle7x7 = cv2.getStructuringElement(cv2.MORPH_RECT,(7,7))        \n",
    "        strucEle15x15 = cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n",
    "        \n",
    "        # Next, we perform dilation and erosion on this\n",
    "        \n",
    "        for i in range(2):\n",
    "            imgThresh = cv2.dilate(imgThresh,strucEle5x5,iterations = 2)\n",
    "            imgThresh = cv2.erode(imgThresh,strucEle5x5,iterations = 1)\n",
    "        \n",
    "        imgThreshCopy = imgThresh.copy()\n",
    "        if(SHOW_DEBUG_STEPS):        \n",
    "            print ('imgThreshCopy height' + str(imgThreshCopy.shape[0]))\n",
    "            print ('imgThreshCopy width' + str(imgThreshCopy.shape[1]))\n",
    "            \n",
    "            \n",
    "        # Now, we move on to the contour mapping portion    \n",
    "        \n",
    "        im, contours, hierarchy = cv2.findContours(imgThreshCopy,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        im2 = drawAndShowContours(wd,ht,contours,'imgContours')\n",
    "            \n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            print ('contours.shape: ' + str(len(contours)))\n",
    "            \n",
    "            \n",
    "        # Next, we define hulls.\n",
    "        # Hulls are contours with the \"convexHull\" function from cv2\n",
    "        \n",
    "        hulls = contours # does it work?\n",
    "        for i in range(len(contours)):\n",
    "            hulls[i] = cv2.convexHull(contours[i])\n",
    "            \n",
    "        # Then we draw the contours    \n",
    "        \n",
    "        im3 = drawAndShowContours(wd,ht,hulls,'imgConvexHulls')\n",
    "        \n",
    "        # Next, we move to blobs\n",
    "        # First, each hull is passed through the Blob function\n",
    "            \n",
    "        for hull in hulls:\n",
    "            # This is an instance of the class Blob()\n",
    "            possiBlob = Blob()\n",
    "            # This is the Blob function inside the class Blob()\n",
    "            possiBlob.Blob(hull) # does it work? yes\n",
    "            currentBoundingRectArea = possiBlob.currentBoundingRect[2] * possiBlob.currentBoundingRect[3] \n",
    "            contourArea = cv2.contourArea(hull)\n",
    "            # These are the conditions which determine whether a hull can satisfactorily be called a Blob\n",
    "            if(currentBoundingRectArea > 400 and possiBlob.dblCurrentAspectRatio > 0.2 and possiBlob.dblCurrentAspectRatio < 4.0 and possiBlob.currentBoundingRect[2] > 30 and possiBlob.currentBoundingRect[3] > 30 and possiBlob.dblCurrentDiagonalSize > 60.0 and (contourArea/int(currentBoundingRectArea) > 0.5)):\n",
    "                currentFrameBlobs.append(possiBlob)\n",
    "        \n",
    "        # Now, using the hulls, we draw the blob objects.\n",
    "        \n",
    "        im4 = drawAndShowBlobs(wd,ht,currentFrameBlobs,'imgCurrentFrameBlobs')\n",
    "            \n",
    "        if blnFirstFrame ==  True:\n",
    "            for currFrameBlob in currentFrameBlobs:\n",
    "                blobs.append(currFrameBlob)\n",
    "        else:\n",
    "            matchCurrentFrameBlobsToExistingBlobs(blobs, currentFrameBlobs)\n",
    "        \n",
    "        im5 = drawAndShowBlobs(wd,ht, blobs, \"imgBlobs\")\n",
    "        \n",
    "        img2 = fFrame2.copy()\n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            print ('img2 height' + str(img2.shape[0]))\n",
    "            print ('img2 width' + str(img2.shape[1]))\n",
    "        \n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        drawBlobInfoOnImage(blobs, img2, fFrame2, frameCnt, fps)\n",
    "        \n",
    "        # Now, we assign the Boolean variable to whether the Blob has crossed the line we drew or not\n",
    "        \n",
    "        #blnAtLeastOneBlobCrossedTheLine = checkIfBlobsCrossedTheLine(blobs, /*intHorizontalLinePosition,*/ vehicleCount)\n",
    "        blnAtLeastOneBlobCrossedTheLine = checkIfBlobsCrossedTheLine(blobs)\n",
    "        \n",
    "        # \n",
    "        \n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            print ('type: ')\n",
    "            print (type(crossingLine[0]))\n",
    "        if blnAtLeastOneBlobCrossedTheLine == True:\n",
    "#            cv2.line(img2, (crossingLine[0]), (crossingLine[1]),(0,255,0),2)\n",
    "            cv2.line(img2, (point1[0],point1[1]),(point2[0],point2[1]),SCALAR_GREEN,2)\n",
    "        else:\n",
    "            cv2.line(img2, (point1[0],point1[1]),(point2[0],point2[1]),SCALAR_RED,2)\n",
    "            \n",
    "        # drawvehicleCountOnImage(img2)\n",
    "        drawMyLine(img2) # is it necessary?\n",
    "        \n",
    "        cv2.imshow(src_window,img2)\n",
    "        \n",
    "        currentFrameBlobs[:]=[] # clear list\n",
    "        \n",
    "        fFrame1 = fFrame2.copy()\n",
    "        ret, fFrame2 = cap.read()\n",
    "        retn(ret)\n",
    "        frm(fFrame2)\n",
    "        #fFrame2 = cv2.resize(fFrame2, (0,0), fx=0.5, fy=0.5) \n",
    "        if(SHOW_DEBUG_STEPS):\n",
    "            print ('img1 height' + str(fFrame1.shape[0]))\n",
    "            print ('img1 width' + str(fFrame1.shape[1]))\n",
    "            print ('img2 height' + str(fFrame2.shape[0]))\n",
    "            print ('img2 width' + str(fFrame2.shape[1]))        \n",
    "        \n",
    "        blnFirstFrame = False\n",
    "        frameCnt = frameCnt + 1\n",
    "    \n",
    "    k = cv2.waitKey(1) \n",
    "    if k == 27 or k == ord('q') or vehicleCount > 20:\n",
    "        closeAll()\n",
    "        break\n",
    "        \n",
    "closeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
